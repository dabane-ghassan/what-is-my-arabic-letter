{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.ndimage import rotate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_data(data: torch.Tensor, label: torch.Tensor, n: int) -> plt.Figure:\n",
    "    \n",
    "    arab_labs = ['أ', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط' , 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى']\n",
    "\n",
    "    fig, axs = plt.subplots(1, n, figsize=(21, 5))\n",
    "    for i_ax, ax in enumerate(axs):\n",
    "        ax.imshow(data[i_ax, :, :, :], cmap=plt.gray())\n",
    "        ax.set_title(\"Label = %s\" % (arab_labs[int(label[i_ax].item())]))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    return fig\n",
    "\n",
    "\n",
    "def view_data_rand(loader: torch.utils.data.DataLoader, n: int = 10) -> plt.Figure:\n",
    "\n",
    "    rand_data, rand_label = next(iter(loader))\n",
    "\n",
    "    return view_data(rand_data, rand_label, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = rotate(np.flip(\n",
    "    pd.read_csv(\"../dataset/csvTrainImages 13440x1024.csv\",\n",
    "                header=None).values.astype('float32').reshape([-1, 32, 32, 1]),\n",
    "    1),\n",
    "                -90,\n",
    "                axes=(1, 2))\n",
    "trainy = pd.read_csv(\"../dataset/csvTrainLabel 13440x1.csv\",\n",
    "                     header=None).values.astype('int32') - 1\n",
    "\n",
    "testx = rotate(np.flip(\n",
    "    pd.read_csv(\"../dataset/csvTestImages 3360x1024.csv\",\n",
    "                header=None).values.astype('float32').reshape([-1, 32, 32, 1]),\n",
    "    1),\n",
    "               -90,\n",
    "               axes=(1, 2))\n",
    "testy = pd.read_csv(\"../dataset/csvTestLabel 3360x1.csv\",\n",
    "                    header=None).values.astype('int32') - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = TensorDataset(torch.Tensor(trainx), torch.Tensor(trainy))\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1512x360 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plts = view_data_rand(train_loader, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Network (Sins and Bros certified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinsNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(SinsNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(1024, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 5, 5], expected input[100, 32, 32, 1] to have 1 channels, but got 32 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1dde1b99076d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-10f11e5d4f37>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 5, 5], expected input[100, 32, 32, 1] to have 1 channels, but got 32 channels instead"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "acc_list = []\n",
    "model = SinsNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, len(train_loader), loss.item(),\n",
    "                          (correct / total) * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
